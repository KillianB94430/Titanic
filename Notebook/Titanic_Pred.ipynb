{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8117deb9-6386-4048-99e5-528ef113b4c2",
   "metadata": {},
   "source": [
    "##  Importer les bibliothèques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "61f64df0-64f7-4701-b995-4dfdf6466a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b62b5d9f-20e4-4fd9-9980-17862b6242fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_df = pd.read_csv('../Data/test.csv')\n",
    "\n",
    "print(test_df.columns)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Remplir les valeurs manquantes pour 'Age' avec la médiane\n",
    "\n",
    "test_df['Age'].fillna(test_df['Age'].median(), inplace=True)\n",
    "\n",
    "# Remplir les valeurs manquantes pour 'Embarked' avec la valeur la plus fréquente\n",
    "test_df['Embarked'].fillna(test_df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Remplir les valeurs manquantes pour 'Fare' dans le jeu de test avec la médiane\n",
    "test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)\n",
    "\n",
    "# Supprimer la colonne 'Cabin' car elle contient trop de valeurs manquantes\n",
    "test_df.drop('Cabin', axis=1, inplace=True)\n",
    "\n",
    "# Créer une nouvelle feature 'FamilySize' à partir de 'SibSp' et 'Parch'\n",
    "test_df['FamilySize'] = test_df['SibSp'] + test_df['Parch'] + 1\n",
    "\n",
    "# Créer une nouvelle feature 'IsAlone' à partir de 'FamilySize'\n",
    "test_df['IsAlone'] = 1\n",
    "test_df.loc[test_df['FamilySize'] > 1, 'IsAlone'] = 0\n",
    "\n",
    "# Supprimer les colonnes inutiles\n",
    "test_df = test_df.drop(['Name', 'Ticket', 'SibSp', 'Parch'], axis=1)\n",
    "\n",
    "# Convertir la feature 'Sex' en numérique\n",
    "test_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1}).astype(int)\n",
    "\n",
    "# Convertir la feature 'Embarked' en numérique en utilisant le one-hot encoding (à voir les tech)\n",
    "test_df = pd.get_dummies(test_df, columns=['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7a73250a-c792-4790-b55f-8d5473d96f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "81fd2111-7874-461e-b902-32330958c29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<RegisteredModel: aliases={}, creation_timestamp=1719820693892, description=None, last_updated_timestamp=1720085327596, latest_versions=[<ModelVersion: aliases=[], creation_timestamp=1720085327596, current_stage='None', description=None, last_updated_timestamp=1720085327596, name='TitanicModel2', run_id='cd8c5481a35e4555815fd2da157ddbaf', run_link=None, source='runs:/cd8c5481a35e4555815fd2da157ddbaf/model', status='READY', status_message=None, tags={}, user_id=None, version=15>], name='TitanicModel2', tags={}>]\n",
      "--------------------------------------------------------------------------------\n",
      "name=TitanicModel2; run_id=cd8c5481a35e4555815fd2da157ddbaf; version=15\n"
     ]
    }
   ],
   "source": [
    "client = MlflowClient()\n",
    "model_name = \"TitanicModel2\"\n",
    "filter_string = f\"name='{model_name}'\"\n",
    "results = client.search_registered_models(filter_string=filter_string)\n",
    "print(results)\n",
    "print(\"-\" * 80)\n",
    "for res in results:\n",
    "    for mv in res.latest_versions:\n",
    "        run_id=mv.run_id\n",
    "        print(f\"name={mv.name}; run_id={mv.run_id}; version={mv.version}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e2f919-2b2f-4307-9ccd-16795c9689aa",
   "metadata": {},
   "source": [
    "##  Charger le modèle depuis MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f7f74ffa-8499-493b-b501-388447ac0af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<RegisteredModel: aliases={}, creation_timestamp=1719820693892, description=None, last_updated_timestamp=1720085327596, latest_versions=[<ModelVersion: aliases=[], creation_timestamp=1720085327596, current_stage='None', description=None, last_updated_timestamp=1720085327596, name='TitanicModel2', run_id='cd8c5481a35e4555815fd2da157ddbaf', run_link=None, source='runs:/cd8c5481a35e4555815fd2da157ddbaf/model', status='READY', status_message=None, tags={}, user_id=None, version=15>], name='TitanicModel2', tags={}>]\n",
      "last_model_uri : runs:/cd8c5481a35e4555815fd2da157ddbaf/model\n"
     ]
    }
   ],
   "source": [
    "registered_versions = mlflow_client.search_registered_models(filter_string=filter_string,\n",
    "    order_by=([\"last_updated_timestamp DESC\"]))\n",
    "print(registered_versions)\n",
    "last_model_uri=registered_versions[0].latest_versions[-1].source    \n",
    "print(f\"last_model_uri : {last_model_uri}\")    # Load the appropriate model identified above    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "81bf60b0-ad96-4d23-b786-c03d44b7c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle depuis MLflow\n",
    "loaded_model = mlflow.sklearn.load_model(last_model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8ce1b9-5617-44e1-99b1-60a803410412",
   "metadata": {},
   "source": [
    "## Appliquer le modèle pour faire des prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0f14f474-e511-4005-a625-cc04569774e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les prédictions ont été enregistrées dans submission_pred.csv\n"
     ]
    }
   ],
   "source": [
    "# Appliquer le modèle pour faire des prédictions\n",
    "predictions = loaded_model.predict(test_df)\n",
    "\n",
    "# Générer le fichier submission.csv\n",
    "submission_pred = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': predictions})\n",
    "submission_pred.to_csv('../Results/submission_pred.csv', index=False)\n",
    "\n",
    "print(\"Les prédictions ont été enregistrées dans submission_pred.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mon_projet_env",
   "language": "python",
   "name": "mon_projet_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
