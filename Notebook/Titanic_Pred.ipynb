{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8117deb9-6386-4048-99e5-528ef113b4c2",
   "metadata": {},
   "source": [
    "##  Importer les bibliothèques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "61f64df0-64f7-4701-b995-4dfdf6466a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b62b5d9f-20e4-4fd9-9980-17862b6242fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../Data/train.csv')\n",
    "test_df = pd.read_csv('../Data/test.csv')\n",
    "print(train_df.columns)\n",
    "print(test_df.columns)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Vérifier la présence de la colonne 'Embarked'\n",
    "if 'Embarked' in train_df.columns:\n",
    "    # Remplir les valeurs manquantes pour 'Embarked' avec la valeur la plus fréquente (si présente)\n",
    "    train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)\n",
    "else:\n",
    "    print(\"La colonne 'Embarked' n'est pas présente dans train_df\")\n",
    "\n",
    "if 'Embarked' in test_df.columns:\n",
    "    test_df['Embarked'].fillna(test_df['Embarked'].mode()[0], inplace=True)\n",
    "else:\n",
    "    print(\"La colonne 'Embarked' n'est pas présente dans test_df\")\n",
    "\n",
    "# Remplir les valeurs manquantes pour 'Age' avec la médiane\n",
    "train_df['Age'].fillna(train_df['Age'].median(), inplace=True)\n",
    "test_df['Age'].fillna(test_df['Age'].median(), inplace=True)\n",
    "\n",
    "# Remplir les valeurs manquantes pour 'Embarked' avec la valeur la plus fréquente\n",
    "train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)\n",
    "test_df['Embarked'].fillna(test_df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Remplir les valeurs manquantes pour 'Fare' dans le jeu de test avec la médiane\n",
    "test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)\n",
    "\n",
    "# Supprimer la colonne 'Cabin' car elle contient trop de valeurs manquantes\n",
    "train_df.drop('Cabin', axis=1, inplace=True)\n",
    "test_df.drop('Cabin', axis=1, inplace=True)\n",
    "\n",
    "# Créer une nouvelle feature 'FamilySize' à partir de 'SibSp' et 'Parch'\n",
    "train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1\n",
    "test_df['FamilySize'] = test_df['SibSp'] + test_df['Parch'] + 1\n",
    "\n",
    "# Créer une nouvelle feature 'IsAlone' à partir de 'FamilySize'\n",
    "train_df['IsAlone'] = 1\n",
    "train_df.loc[train_df['FamilySize'] > 1, 'IsAlone'] = 0\n",
    "test_df['IsAlone'] = 1\n",
    "test_df.loc[test_df['FamilySize'] > 1, 'IsAlone'] = 0\n",
    "\n",
    "# Supprimer les colonnes inutiles\n",
    "train_df = train_df.drop(['Name', 'Ticket', 'SibSp', 'Parch'], axis=1)\n",
    "test_df = test_df.drop(['Name', 'Ticket', 'SibSp', 'Parch'], axis=1)\n",
    "\n",
    "# Convertir la feature 'Sex' en numérique\n",
    "train_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1}).astype(int)\n",
    "test_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1}).astype(int)\n",
    "\n",
    "# Convertir la feature 'Embarked' en numérique en utilisant le one-hot encoding (à voir les tech)\n",
    "train_df = pd.get_dummies(train_df, columns=['Embarked'])\n",
    "test_df = pd.get_dummies(test_df, columns=['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7a73250a-c792-4790-b55f-8d5473d96f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop('Survived', axis=1)\n",
    "y = train_df['Survived']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e2f919-2b2f-4307-9ccd-16795c9689aa",
   "metadata": {},
   "source": [
    "##  Charger le modèle depuis MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "81fd2111-7874-461e-b902-32330958c29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<RegisteredModel: aliases={}, creation_timestamp=1719820693892, description=None, last_updated_timestamp=1720017205620, latest_versions=[<ModelVersion: aliases=[], creation_timestamp=1720017205620, current_stage='None', description=None, last_updated_timestamp=1720017205620, name='TitanicModel2', run_id='dfeff3f8b99a4c86a2069522950553b5', run_link=None, source='runs:/dfeff3f8b99a4c86a2069522950553b5/model', status='READY', status_message=None, tags={}, user_id=None, version=12>], name='TitanicModel2', tags={}>]\n",
      "--------------------------------------------------------------------------------\n",
      "name=TitanicModel2; run_id=dfeff3f8b99a4c86a2069522950553b5; version=12\n"
     ]
    }
   ],
   "source": [
    "mlflow_client = MlflowClient()\n",
    "model_name = \"TitanicModel2\"\n",
    "filter_string = f\"name='{model_name}'\"\n",
    "results = client.search_registered_models(filter_string=filter_string)\n",
    "print(results)\n",
    "print(\"-\" * 80)\n",
    "for res in results:\n",
    "    for mv in res.latest_versions:\n",
    "        run_id=mv.run_id\n",
    "        print(f\"name={mv.name}; run_id={mv.run_id}; version={mv.version}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f7f74ffa-8499-493b-b501-388447ac0af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<RegisteredModel: aliases={}, creation_timestamp=1719820693892, description=None, last_updated_timestamp=1720017205620, latest_versions=[<ModelVersion: aliases=[], creation_timestamp=1720017205620, current_stage='None', description=None, last_updated_timestamp=1720017205620, name='TitanicModel2', run_id='dfeff3f8b99a4c86a2069522950553b5', run_link=None, source='runs:/dfeff3f8b99a4c86a2069522950553b5/model', status='READY', status_message=None, tags={}, user_id=None, version=12>], name='TitanicModel2', tags={}>]\n",
      "last_model_uri : runs:/dfeff3f8b99a4c86a2069522950553b5/model\n"
     ]
    }
   ],
   "source": [
    "registered_versions = mlflow_client.search_registered_models(filter_string=filter_string,\n",
    "    order_by=([\"last_updated_timestamp DESC\"]))\n",
    "print(registered_versions)\n",
    "last_model_uri=registered_versions[0].latest_versions[-1].source    \n",
    "print(f\"last_model_uri : {last_model_uri}\")    # Load the appropriate model identified above    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "81bf60b0-ad96-4d23-b786-c03d44b7c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle depuis MLflow\n",
    "loaded_model = mlflow.sklearn.load_model(last_model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46692256-5835-4c52-b9d9-7806b97ff934",
   "metadata": {},
   "source": [
    "## Préparer les nouvelles données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8ce1b9-5617-44e1-99b1-60a803410412",
   "metadata": {},
   "source": [
    "## Appliquer le modèle pour faire des prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0f14f474-e511-4005-a625-cc04569774e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array length 891 does not match index length 89",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m loaded_model\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Générer le fichier submission.csv\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m submission_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPassengerId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPassengerId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSurvived\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m submission_pred\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/submission_pred.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLes prédictions ont été enregistrées dans submission_pred.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/titanic-obvIVfry-py3.12/lib/python3.12/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/titanic-obvIVfry-py3.12/lib/python3.12/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/titanic-obvIVfry-py3.12/lib/python3.12/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/titanic-obvIVfry-py3.12/lib/python3.12/site-packages/pandas/core/internals/construction.py:690\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lengths[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m    686\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    687\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlengths[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    688\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    689\u001b[0m         )\n\u001b[0;32m--> 690\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(lengths[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: array length 891 does not match index length 89"
     ]
    }
   ],
   "source": [
    "# Appliquer le modèle pour faire des prédictions\n",
    "predictions = loaded_model.predict(X)\n",
    "\n",
    "# Générer le fichier submission.csv\n",
    "submission_pred = pd.DataFrame({'PassengerId': new_data['PassengerId'], 'Survived': predictions})\n",
    "submission_pred.to_csv('/submission_pred.csv', index=False)\n",
    "\n",
    "print(\"Les prédictions ont été enregistrées dans submission_pred.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07d76ac-beef-45d2-8770-e0c324f2044e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mon_projet_env",
   "language": "python",
   "name": "mon_projet_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
